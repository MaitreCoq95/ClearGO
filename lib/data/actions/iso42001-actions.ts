// ISO 42001 Corrective Actions - AI Governance
import { ActionSet } from "./types"

export const ISO42001_ACTIONS: ActionSet = {
  standard: "ISO_42001",
  standardName: "ISO 42001",
  actions: [
    // Context
    {
      id: "ai-ctx-1",
      sectionId: "context",
      title: "Stratégie IA de l'organisation",
      description: "Formaliser la stratégie et les objectifs IA.",
      priority: "critical",
      category: "documentation",
      estimatedHours: 16,
      effort: "high",
      deliverables: ["Stratégie IA", "Feuille de route", "KPIs"],
    },
    {
      id: "ai-ctx-2",
      sectionId: "context",
      title: "Registre des systèmes IA",
      description: "Inventorier tous les cas d'usage IA de l'organisation.",
      priority: "critical",
      category: "documentation",
      estimatedHours: 12,
      effort: "medium",
      deliverables: ["Registre des IA", "Classification par risque"],
    },
    // Risk
    {
      id: "ai-risk-1",
      sectionId: "risk",
      title: "Framework d'évaluation des risques IA",
      description: "Créer une méthodologie d'évaluation des risques spécifiques IA.",
      priority: "critical",
      category: "process",
      estimatedHours: 24,
      effort: "high",
      deliverables: ["Méthodologie", "Grille d'évaluation", "Registre des risques"],
    },
    {
      id: "ai-risk-2",
      sectionId: "risk",
      title: "Étude d'impact droits humains (HRIA)",
      description: "Évaluer les impacts potentiels sur les droits fondamentaux.",
      priority: "critical",
      category: "documentation",
      estimatedHours: 20,
      effort: "high",
      deliverables: ["Rapport HRIA", "Mesures d'atténuation"],
    },
    {
      id: "ai-risk-3",
      sectionId: "risk",
      title: "Classification des systèmes selon l'AI Act",
      description: "Classifier les systèmes selon les niveaux de risque UE.",
      priority: "high",
      category: "process",
      estimatedHours: 8,
      effort: "medium",
      deliverables: ["Matrice de classification", "Exigences par niveau"],
    },
    // Data
    {
      id: "ai-data-1",
      sectionId: "data",
      title: "Politique de gouvernance des données IA",
      description: "Établir les règles de gestion des données d'entraînement.",
      priority: "critical",
      category: "documentation",
      estimatedHours: 16,
      effort: "high",
      deliverables: ["Politique data", "Exigences qualité"],
    },
    {
      id: "ai-data-2",
      sectionId: "data",
      title: "Processus de détection des biais",
      description: "Mettre en place des outils de détection des biais.",
      priority: "critical",
      category: "process",
      estimatedHours: 24,
      effort: "high",
      deliverables: ["Processus bias detection", "Outils", "Métriques"],
    },
    {
      id: "ai-data-3",
      sectionId: "data",
      title: "Data lineage et traçabilité",
      description: "Assurer la traçabilité des données utilisées.",
      priority: "high",
      category: "infrastructure",
      estimatedHours: 16,
      effort: "high",
      deliverables: ["Système de traçabilité", "Documentation datasets"],
    },
    // Development
    {
      id: "ai-dev-1",
      sectionId: "development",
      title: "Processus MLOps",
      description: "Structurer le cycle de vie ML avec CI/CD.",
      priority: "critical",
      category: "process",
      estimatedHours: 40,
      effort: "high",
      deliverables: ["Pipeline MLOps", "Procédures", "Tests automatisés"],
    },
    {
      id: "ai-dev-2",
      sectionId: "development",
      title: "Framework de tests et validation IA",
      description: "Établir les critères de validation des modèles.",
      priority: "critical",
      category: "process",
      estimatedHours: 20,
      effort: "high",
      deliverables: ["Framework de tests", "Critères d'acceptation"],
    },
    {
      id: "ai-dev-3",
      sectionId: "development",
      title: "Explainability (XAI)",
      description: "Implémenter des solutions d'explicabilité.",
      priority: "high",
      category: "infrastructure",
      estimatedHours: 24,
      effort: "high",
      deliverables: ["Solutions XAI", "Documentation décisions"],
    },
    {
      id: "ai-dev-4",
      sectionId: "development",
      title: "Monitoring des modèles en production",
      description: "Surveiller la dérive et les performances.",
      priority: "high",
      category: "infrastructure",
      estimatedHours: 16,
      effort: "high",
      deliverables: ["Dashboard monitoring", "Alertes drift"],
    },
    // Ethics
    {
      id: "ai-eth-1",
      sectionId: "ethics",
      title: "Charte éthique IA",
      description: "Rédiger et diffuser les principes éthiques IA.",
      priority: "critical",
      category: "documentation",
      estimatedHours: 12,
      effort: "medium",
      deliverables: ["Charte éthique", "Communication"],
    },
    {
      id: "ai-eth-2",
      sectionId: "ethics",
      title: "Comité éthique IA",
      description: "Créer une instance de gouvernance éthique.",
      priority: "high",
      category: "management",
      estimatedHours: 8,
      effort: "medium",
      deliverables: ["Charte du comité", "Membres", "Processus de saisine"],
    },
    {
      id: "ai-eth-3",
      sectionId: "ethics",
      title: "Conformité AI Act",
      description: "Plan de mise en conformité avec le règlement IA.",
      priority: "critical",
      category: "process",
      estimatedHours: 40,
      effort: "high",
      deliverables: ["Gap analysis", "Plan d'action", "Documentation technique"],
    },
    {
      id: "ai-eth-4",
      sectionId: "ethics",
      title: "Human-in-the-loop",
      description: "Mettre en place la supervision humaine des décisions IA.",
      priority: "critical",
      category: "process",
      estimatedHours: 16,
      effort: "high",
      deliverables: ["Processus HITL", "Critères d'escalade"],
    },
  ]
}

export default ISO42001_ACTIONS
